{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73b9813b",
   "metadata": {},
   "source": [
    "# PREPARATION OF PRODUCTION CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b66f3a",
   "metadata": {},
   "source": [
    "Goal: Prepare the final, production-ready pipeline for the RUL prediction model.\n",
    "\n",
    "Key idea:\n",
    "- Pandas-based operations are done before the pipeline (data cleaning, and changing structure).\n",
    "- scikit-learn transformations are done inside the pipeline (for modeling). \n",
    "\n",
    "\n",
    "Our approach at this stage is:\n",
    "\n",
    "1. **Load the raw dataset.** Read original data (no preprocessing applied). \n",
    "\n",
    "\n",
    "2. **Transformations in the structure (outside the pipeline, with pandas)**\n",
    "- Correct column names\n",
    "- Remove duplicates and nulls (not needed in this project)\n",
    "- Restrict the dataset to final selected variables\n",
    "- Create the target variable (RUL) (and declare X and y)\n",
    "\n",
    "3. **Create the pipeline and include transformations in the data (with Sklearn)**, such as:\n",
    "- imputations, encodings, and scalings using scikit-learn transformers (only standard scaling in this project)\n",
    "\n",
    "4. **Integrate the model within the pipeline**\n",
    "\n",
    " \n",
    "5. **Save the final execution-ready pipeline and store it for retraining or production use**\n",
    "\n",
    "After this, there will be only 2 notebooks more, which are actually 2 scripts, in which we paste what we preparated in this notebook:\n",
    "- 08_Retraining Code\n",
    "- 09_Execution Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ae63f",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe7be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cloudpickle  # alternative to Pickle that also allows saving custom Pandas functions\n",
    "\n",
    "#Enable fast autocomplete\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "#Libraries needed for any project\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#Specific libraries for this example project template:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e12241c",
   "metadata": {},
   "source": [
    "## IMPORT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe9a43",
   "metadata": {},
   "source": [
    "### Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b345d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project path\n",
    "PROJECT_PATH = '/Users/rober/cmapss-rul-prediction'\n",
    "\n",
    "# Dataset selection (FD001, FD002, FD003, or FD004)\n",
    "dataset_id = 'FD001'\n",
    "\n",
    "# Data paths\n",
    "path = PROJECT_PATH + '/02_Data/01_Raw/'\n",
    "train_path = path + f'train_{dataset_id}.txt'\n",
    "\n",
    "# Load datasets\n",
    "df = pd.read_csv(train_path, delim_whitespace=True, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454738c9",
   "metadata": {},
   "source": [
    "### Select only selected variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba546b91",
   "metadata": {},
   "source": [
    "#### Load list of selected variables (saved on previous notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26066884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_in_cycles_ss',\n",
       " 'sensor_11_ss',\n",
       " 'sensor_4_ss',\n",
       " 'sensor_12_ss',\n",
       " 'sensor_7_ss',\n",
       " 'sensor_15_ss',\n",
       " 'sensor_21_ss',\n",
       " 'sensor_20_ss']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_variables_path = PROJECT_PATH + '/05_Results/' + 'selected_variables.pickle'\n",
    "\n",
    "pd.read_pickle(selected_variables_path).sort_index().values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c127d9a",
   "metadata": {},
   "source": [
    "#### List of selected variables without sufixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da477021",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_variables = ['time_in_cycles',\n",
    "                     'sensor_11',\n",
    "                     'sensor_4',\n",
    "                     'sensor_12',\n",
    "                     'sensor_7',\n",
    "                     'sensor_15',\n",
    "                     'sensor_21',\n",
    "                     'sensor_20']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4dd9cb",
   "metadata": {},
   "source": [
    "#### Transformations in selected variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813710a",
   "metadata": {},
   "source": [
    "| |  | time_in_cycles | sensor_11 | sensor_4 | sensor_12 | sensor_7 | sensor_15 | sensor_21 | sensor_20 |\n",
    "| --------------- | ------ | -------------- | --------- | -------- | --------- | -------- | --------- | --------- | --------- |\n",
    "| NAMES           | MANUAL | X              | X         | X        | X         | X        | X         | X         | X         |\n",
    "| TYPES           |        |                | X         | X        | X         | X        | X         | X         | X         |\n",
    "| RESCALING       | SS     | X              | X         | X        | X         | X        | X         | X         | X         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a706b",
   "metadata": {},
   "source": [
    "## STRUCTURAL TRANSFORMATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5555ab2",
   "metadata": {},
   "source": [
    "1. Correct names (original columns have jut numbers as names)\n",
    "2. Create the target (calculate RUL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd09e5",
   "metadata": {},
   "source": [
    "### Correct names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08e56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name columns dynamically\n",
    "\n",
    "n_cols = df.shape[1] # this n_cols is valid for 'test' also\n",
    "n_sensors = n_cols - 5 # first 4 columns are not sensors\n",
    "\n",
    "columns = (\n",
    "    ['unit_number', 'time_in_cycles'] +\n",
    "    [f'op_setting_{i}' for i in range(1, 4)] +\n",
    "    [f'sensor_{i}' for i in range(1, n_sensors + 1)]\n",
    ") # concatenate names to create the whole list of column names ('columns')\n",
    "\n",
    "df.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f16beca",
   "metadata": {},
   "source": [
    "### Create the target and assign X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041d5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last cycle for each engine\n",
    "rul_per_unit = df.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
    "rul_per_unit.columns = ['unit_number', 'max_cycle']\n",
    "\n",
    "# Merge back to the main dataframe\n",
    "df = df.merge(rul_per_unit, on='unit_number', how='left')\n",
    "\n",
    "# Calculate RUL\n",
    "df['RUL'] = df['max_cycle'] - df['time_in_cycles']\n",
    "\n",
    "# Clean up (optional)\n",
    "df.drop(columns=['max_cycle'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90d327",
   "metadata": {},
   "source": [
    "#### For X: index only selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b371a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[selected_variables].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e746ec8d",
   "metadata": {},
   "source": [
    "#### For y: specify the target and create y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a4fd84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable\n",
    "target = 'RUL'\n",
    "\n",
    "# Create y\n",
    "y = df[target].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bb2255",
   "metadata": {},
   "source": [
    "## CREATE THE PIPELINE (for data quality and transformations; not mandatory but efficient) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e8fca",
   "metadata": {},
   "source": [
    "### Instance data quality function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06178080",
   "metadata": {},
   "source": [
    "#### Create the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23feb20f",
   "metadata": {},
   "source": [
    "The only data quality process we did with selected variables was coverting types to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98177b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality(df):\n",
    "    \n",
    "    # Make a copy to avoid mutating original\n",
    "    temp = df.copy()            \n",
    "    \n",
    "    # All sensors to float to unify types\n",
    "    sensor_cols = [col for col in df.columns if 'sensor_' in col]\n",
    "    df[sensor_cols] = df[sensor_cols].astype(float)\n",
    "    \n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd7490",
   "metadata": {},
   "source": [
    "#### Convert the function in a transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6805f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_data_quality = FunctionTransformer(data_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e57147",
   "metadata": {},
   "source": [
    "### Instance transformations in variables (feature engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc435fb4",
   "metadata": {},
   "source": [
    "The only transformation we did with selected variables was standard scalling (rescaling) with all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee711664",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf3f141",
   "metadata": {},
   "source": [
    "### Create the preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b7821",
   "metadata": {},
   "source": [
    "#### Create the column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e577b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ss, selected_variables),\n",
    "    remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de30e37",
   "metadata": {},
   "source": [
    "#### Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e1300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_prepro = make_pipeline(do_data_quality, \n",
    "                            ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b08601",
   "metadata": {},
   "source": [
    "### Instance the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c9e60",
   "metadata": {},
   "source": [
    "#### Instance the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b2e752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HistGradientBoostingRegressor(l2_regularization=0.5,\n",
    "                                      learning_rate=0.025,\n",
    "                                      max_depth=10, max_iter=200,\n",
    "                                      min_samples_leaf=500,\n",
    "                                      scoring='neg_mean_absolute_percentage_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8e2f3",
   "metadata": {},
   "source": [
    "#### Build the final training pipeline (not yet trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0efb038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_training = make_pipeline(pipe_prepro, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0700d8",
   "metadata": {},
   "source": [
    "#### Save the final training pipeline (not yet trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71715e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_training_name = 'pipe_training.pickle'\n",
    "\n",
    "PIPE_TRAINING_PATH = PROJECT_PATH + '/04_Models/' + pipe_training_name\n",
    "\n",
    "with open(PIPE_TRAINING_PATH, mode='wb') as file:\n",
    "   cloudpickle.dump(pipe_training, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e5ed1",
   "metadata": {},
   "source": [
    "#### Train the execution pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13ca2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_execution = pipe_training.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e506db",
   "metadata": {},
   "source": [
    "## SAVE THE PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba8bc8",
   "metadata": {},
   "source": [
    "### Save the execution pipeline (already trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dda8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_execution_name = 'pipe_execution.pickle'\n",
    "\n",
    "PIPE_EXECUTION_PATH = PROJECT_PATH + '/04_Models/' + pipe_execution_name\n",
    "\n",
    "with open(PIPE_EXECUTION_PATH, mode='wb') as file:\n",
    "   cloudpickle.dump(pipe_execution, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717f6d6",
   "metadata": {},
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb3193",
   "metadata": {},
   "source": [
    "We have saved:\n",
    "\n",
    "- **pipe_training**: the untrained pipeline, in case we want to retrain it in the future.\n",
    "- **pipe_execution**: the trained pipeline (already fitted), which we will later use to make predictions.\n",
    "\n",
    "From this point on, we will generate two scripts:\n",
    "\n",
    "- **Retraining**: \n",
    "\n",
    "    - Models gradually lose predictive power over time (data drifts, the market evolves...)\n",
    "    - There is no fixed rule for how often to retrain (e.g., insurance or energy companies may retrain every 5 years, while in digital advertising it can be every few seconds). \n",
    "    - Typically, retraining is triggered when predictive performance drops by 5–10%. \n",
    "    - We’ll keep this code ready, although the one we’ll actually use is the execution script. \n",
    "    \n",
    "\n",
    "- **Execution**: An engineer will deploy this script in a production environment (to run in batch mode, or via API, or as part of an app...)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
